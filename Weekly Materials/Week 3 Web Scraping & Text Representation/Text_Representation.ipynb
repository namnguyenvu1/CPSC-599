{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmOMwqdVJF0p"
      },
      "outputs": [],
      "source": [
        "# Installation, you can choose a particular version as well e.g. scikit-learn==0.21.3\n",
        "#!pip install scikit-learn\n",
        "#!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Corpus"
      ],
      "metadata": {
        "id": "ITW2pIuWJUGb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S4Ircomar27",
        "outputId": "1a0278e6-3409-4a9f-e221-1e86de8fbf39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our corpus:  ['the cat sat on the mat', 'the mat was red', 'the cat liked the mat']\n"
          ]
        }
      ],
      "source": [
        "documents = ['the cat sat on the mat', 'the mat was red', 'the cat liked the mat']\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "\n",
        "#look at the documents list\n",
        "print(\"Our corpus: \", processed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJeMM8SXJF0t"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IwvoK81_JF0t",
        "outputId": "3345aaba-8933-4d55-bcb9-1944d5d2ee25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary {'the': 6, 'cat': 0, 'sat': 5, 'on': 3, 'mat': 2, 'was': 7, 'red': 4, 'liked': 1} \n",
            "\n",
            "Vocabulary index for cat 0 \n",
            "\n",
            "BoW representation for Document 0:  [[1 0 1 1 0 1 2 0]]\n",
            "BoW representation for Document 1:  [[0 0 1 0 1 0 1 1]]\n",
            "BoW representation for Document 2:  [[1 1 1 0 0 0 2 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the count vectorizer object\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "# Build a BOW representation\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "# Print out the vocabulary\n",
        "print(\"Vocabulary\", count_vect.vocabulary_, \"\\n\")\n",
        "\n",
        "print(\"Vocabulary index for cat\", count_vect.vocabulary_.get(\"cat\"), \"\\n\")\n",
        "\n",
        "#see the BOW rep for documents\n",
        "for ind in range(0,len(processed_docs)):\n",
        "    print(\"BoW representation for Document {}: \".format(ind), bow_rep[ind].toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi5yYmhXJF0t"
      },
      "source": [
        "You can also make a dataframe representation to summarize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-RjioM0EJF0u",
        "outputId": "f2883e9b-6095-479a-d2d3-1da481d08fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat  liked  mat  on  red  sat  the  was\n",
            "0    1      0    1   1    0    1    2    0\n",
            "1    0      0    1   0    1    0    1    1\n",
            "2    1      1    1   0    0    0    2    0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_bow = pd.DataFrame(bow_rep.toarray(),columns=count_vect.get_feature_names_out())\n",
        "\n",
        "print(df_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2usLKKjLJF0u"
      },
      "source": [
        "**Exercise:** Try adding another document to this BoW representation. Do you notice anything?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vk-NyJupJF0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b85b225-182b-48f9-f5d0-6744c22c4582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bow representation for 'cat and cat are friends': [[2 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"cat and cat are friends\"])\n",
        "print(\"Bow representation for 'cat and cat are friends':\", temp.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a4ckBaHJF0v"
      },
      "source": [
        "## Bag of N-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r3-6sNEoJF0v",
        "outputId": "796c3717-956a-4df3-8429-00af0c88ecc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  {'the': 18, 'cat': 0, 'sat': 15, 'on': 11, 'mat': 8, 'the cat': 19, 'cat sat': 3, 'sat on': 16, 'on the': 12, 'the mat': 22, 'the cat sat': 21, 'cat sat on': 4, 'sat on the': 17, 'on the mat': 13, 'was': 24, 'red': 14, 'mat was': 9, 'was red': 25, 'the mat was': 23, 'mat was red': 10, 'liked': 5, 'cat liked': 1, 'liked the': 6, 'the cat liked': 20, 'cat liked the': 2, 'liked the mat': 7}\n"
          ]
        }
      ],
      "source": [
        "# Ngram vectorization example with count vectorizer and uni, bi, trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1,3))\n",
        "\n",
        "# Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "# Vocabulary mapping\n",
        "print(\"Vocabulary: \", count_vect.vocabulary_)\n",
        "\n",
        "# See what the results are similar to what we did for BoW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE4VO40Gbl1U"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "TF-IDF allows us to consider that there are some words in a document that are more important than others. This measure quantifies the importance of a given word relative to other words in the document and in the corpus. It was commonly used representation scheme for information retrieval systems, for extracting relevant documents from a corpus for a particular query.\n",
        "\n",
        "It is relatively easy to calculate using TfidfVectorizer in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRjyqt4Ba2zx",
        "outputId": "20acd53d-aef3-483a-8ec8-50f921915a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All words in the vocabulary ['cat' 'liked' 'mat' 'on' 'red' 'sat' 'the' 'was']\n",
            "\n",
            "\n",
            "IDF for all words in the vocabulary [1.28768207 1.69314718 1.         1.69314718 1.69314718 1.69314718\n",
            " 1.         1.69314718]\n",
            "\n",
            "\n",
            "TFIDF representation for all documents in our corpus\n",
            " [[0.36580076 0.         0.28407693 0.48098405 0.         0.48098405\n",
            "  0.56815385 0.        ]\n",
            " [0.         0.         0.35959372 0.         0.6088451  0.\n",
            "  0.35959372 0.6088451 ]\n",
            " [0.4172334  0.54861178 0.32401895 0.         0.         0.\n",
            "  0.64803791 0.        ]]\n",
            "\n",
            "\n",
            "        cat     liked       mat        on       red       sat       the  \\\n",
            "0  0.365801  0.000000  0.284077  0.480984  0.000000  0.480984  0.568154   \n",
            "1  0.000000  0.000000  0.359594  0.000000  0.608845  0.000000  0.359594   \n",
            "2  0.417233  0.548612  0.324019  0.000000  0.000000  0.000000  0.648038   \n",
            "\n",
            "        was  \n",
            "0  0.000000  \n",
            "1  0.608845  \n",
            "2  0.000000  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_docs) #note, you can use n-grams for TF-IDF as well\n",
        "\n",
        "#All words in the vocabulary.\n",
        "print(\"All words in the vocabulary\",tfidf.get_feature_names_out())\n",
        "print(\"\\n\")\n",
        "#IDF for all words in the vocabulary\n",
        "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "#TFIDF representation for all documents in our corpus\n",
        "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray())\n",
        "print(\"\\n\")\n",
        "\n",
        "df_tfidf = pd.DataFrame(bow_rep_tfidf.toarray(),columns=tfidf.get_feature_names_out())\n",
        "\n",
        "print(df_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How is scikit-learn actually calculating these numbers? It doesn't look like what we got from the exercise in the slides.\n",
        "\n",
        "One thing scikit-learn does differently is that for calculating term frequency it just takes the number of times the term appears in a document by default.\n",
        "\n",
        "Secondly, it is accounting for scenarios where a term may appear in all documents of a corpus.\n",
        "\n",
        "Finally, it normalizes its Tf-IDF vectors (L2/Euclidean norm by default) for each document in the corpus."
      ],
      "metadata": {
        "id": "2Px-Zdlmf7wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"the cat sat on the mat\",\n",
        "    \"the mat was red\",\n",
        "    \"the cat liked the mat\"\n",
        "]\n",
        "\n",
        "# Create TfidfVectorizer without normalization\n",
        "tfidf = TfidfVectorizer(norm=None)\n",
        "\n",
        "# Fit and transform the documents\n",
        "tfidf_matrix_unnormalized = tfidf.fit_transform(documents)\n",
        "\n",
        "# Convert the TF-IDF matrix to an array for better visualization\n",
        "tfidf_array_unnormalized = tfidf_matrix_unnormalized.toarray()\n",
        "\n",
        "#unnormalized\n",
        "print(\"Un-normalized TF-IDF matrix:\")\n",
        "print(pd.DataFrame(tfidf_array_unnormalized,columns=tfidf.get_feature_names_out()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSmBDnqEZXV_",
        "outputId": "b4556918-fbc3-4587-d3a6-14459e27ba83"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un-normalized TF-IDF matrix:\n",
            "        cat     liked  mat        on       red       sat  the       was\n",
            "0  1.287682  0.000000  1.0  1.693147  0.000000  1.693147  2.0  0.000000\n",
            "1  0.000000  0.000000  1.0  0.000000  1.693147  0.000000  1.0  1.693147\n",
            "2  1.287682  1.693147  1.0  0.000000  0.000000  0.000000  2.0  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDF: log((1 + N)/(1+df(term)) + 1\n",
        "\n",
        "For term cat:\n",
        "\n",
        "              log(3/2) = 0.405465 (traditional calculation)\n",
        "\n",
        "              log(4/3) + 1 = 1.28768207 (scikit-learn)\n",
        "\n",
        "For term mat:\n",
        "              \n",
        "              log(3/3) = 0 (traditional calculation)\n",
        "\n",
        "              log(4/4) + 1 = 1.0 (scikit-learn)\n"
      ],
      "metadata": {
        "id": "fCA7Yc-mvEeq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmAkT17UJF0w"
      },
      "source": [
        "What if the document doesn't exist?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r1A_xnFMJF0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc52f87e-2dad-4980-ce71-b97d1e205827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "        cat  liked  mat   on       red  sat       the       was\n",
            "0  0.444514    0.0  0.0  0.0  0.584483  0.0  0.345205  0.584483\n"
          ]
        }
      ],
      "source": [
        "new_document = ['a new document with OOV words']\n",
        "\n",
        "#transform the new document using the current vocabulary\n",
        "tfidf_new = tfidf.transform(new_document)\n",
        "print(tfidf_new.toarray())\n",
        "\n",
        "new_document = ['the red cat was nice']\n",
        "\n",
        "tfidf_new = tfidf.transform(new_document)\n",
        "df_tfidf = pd.DataFrame(tfidf_new.toarray(),columns=tfidf.get_feature_names_out())\n",
        "\n",
        "print(df_tfidf)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}